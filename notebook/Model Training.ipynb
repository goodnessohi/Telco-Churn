{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e635eb9c",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facedc70",
   "metadata": {},
   "source": [
    "#### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73df087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, recall_score, confusion_matrix,\n",
    "    roc_auc_score, precision_score, f1_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5772835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/Telco Churn Data.csv')\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8b0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to numeric, filling NaN values\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'].fillna(df['tenure'] * df['MonthlyCharges'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de56acb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61dbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.drop(columns=['customerID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a165f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SeniorCitizen to object\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de580cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'No phone service' and 'No internet service' with 'No' for certain columns\n",
    "df['MultipleLines'] = df['MultipleLines'].replace('No phone service', 'No')\n",
    "columns_to_replace = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "for column in columns_to_replace:\n",
    "    df[column] = df[column].replace('No internet service', 'No')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678f88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Churn' categorical variable to numeric\n",
    "df['Churn'] = df['Churn'].replace({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5e2789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   object \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   MultipleLines     7043 non-null   object \n",
      " 7   InternetService   7043 non-null   object \n",
      " 8   OnlineSecurity    7043 non-null   object \n",
      " 9   OnlineBackup      7043 non-null   object \n",
      " 10  DeviceProtection  7043 non-null   object \n",
      " 11  TechSupport       7043 non-null   object \n",
      " 12  StreamingTV       7043 non-null   object \n",
      " 13  StreamingMovies   7043 non-null   object \n",
      " 14  Contract          7043 non-null   object \n",
      " 15  PaperlessBilling  7043 non-null   object \n",
      " 16  PaymentMethod     7043 non-null   object \n",
      " 17  MonthlyCharges    7043 non-null   float64\n",
      " 18  TotalCharges      7043 non-null   float64\n",
      " 19  Churn             7043 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(16)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd302b",
   "metadata": {},
   "source": [
    "### Create the StratifiedShuffleSplit object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a67a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02e3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features)\n",
    "               \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b8cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16e1416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd7390cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=64)\n",
    "\n",
    "for train_index, test_index in sss.split(X_scaled, y):\n",
    "    X_train_scaled, X_test_scaled = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9b73bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5634, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f974ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on churn prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array): True labels\n",
    "    y_pred (array): Predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Classification Report': classification_report(y_true, y_pred),\n",
    "        'Confusion Matrix': confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fba6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define different models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"CatBoost\": CatBoostClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7bca4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Logistic Regression**\n",
      "Accuracy: 0.8112\n",
      "Precision: 0.6875\n",
      "Recall: 0.5294\n",
      "F1 Score: 0.5982\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88      1035\n",
      "           1       0.69      0.53      0.60       374\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.77      0.72      0.74      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[945  90] [176 198]]\n",
      "\n",
      "**CatBoost**\n",
      "Accuracy: 0.7828\n",
      "Precision: 0.6126\n",
      "Recall: 0.4947\n",
      "F1 Score: 0.5473\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1035\n",
      "           1       0.61      0.49      0.55       374\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.69      0.70      1409\n",
      "weighted avg       0.77      0.78      0.77      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[918 117] [189 185]]\n",
      "\n",
      "**XGBoost**\n",
      "Accuracy: 0.7686\n",
      "Precision: 0.5741\n",
      "Recall: 0.4973\n",
      "F1 Score: 0.5330\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1035\n",
      "           1       0.57      0.50      0.53       374\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.70      0.68      0.69      1409\n",
      "weighted avg       0.76      0.77      0.76      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[897 138] [188 186]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    if name == \"CatBoost\":\n",
    "        model.fit(X_train_scaled, y_train, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    # Remove \"learn\" lines from metrics\n",
    "    if 'Confusion Matrix' in metrics:\n",
    "        metrics['Confusion Matrix'] = str(metrics['Confusion Matrix']).replace('\\n', '')\n",
    "    \n",
    "    # Print organized output\n",
    "    print(f\"**{name}**\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{metrics['Classification Report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['Confusion Matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c627b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32fab55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "with open('logistic_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(LogisticRegression, file)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24c2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
